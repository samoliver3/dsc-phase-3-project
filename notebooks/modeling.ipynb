{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('..\\\\data\\\\telecom_data.csv')\n",
    "\n",
    "# Handle object types for international plan and voice mail plan\n",
    "df.loc[df['international plan'] == 'no', 'international plan'] = 0\n",
    "df.loc[df['international plan'] == 'yes', 'international plan'] = 1 \n",
    "\n",
    "df.loc[df['voice mail plan'] == 'no', 'voice mail plan'] = 0\n",
    "df.loc[df['voice mail plan']== 'yes', 'voice mail plan'] = 1\n",
    "\n",
    "# Change churn to values: 1 (churned/True) 0 (no churn/False)\n",
    "df.loc[df['churn'] == True, 'churn'] = 1\n",
    "df.loc[df['churn'] == False, 'churn'] = 0\n",
    "\n",
    "# going to create backup df and drop phone number from original df\n",
    "# phone number could be used as unique id, but it doesn't seem necessary\n",
    "df_backup = df.copy()\n",
    "df = df.drop(['phone number'], axis=1)\n",
    "\n",
    "# casting int values to churn, voice mail plan, and international plan cols\n",
    "objs = ['international plan', 'voice mail plan', 'churn']\n",
    "\n",
    "for o in objs:\n",
    "    df = df.astype({o: int})\n",
    "    \n",
    "# dropping area code\n",
    "df = df.drop(['area code'], axis=1)\n",
    "\n",
    "# check df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle international calls to bin them into categories easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle international calls to bin them into categories easier.\n",
    "df['total intl calls'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['total intl calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total intl calls'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# range is 0-20 for international calls with most concentrated from 0-10\n",
    "# I will bin into cats: low, moderate, and high with values <3, 3-6, and >6\n",
    "\n",
    "list_tmp = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['total intl calls'] < 3:\n",
    "        list_tmp.append('low')\n",
    "    elif row['total intl calls'] > 6:\n",
    "        list_tmp.append('high')\n",
    "    else:\n",
    "        list_tmp.append('moderate')\n",
    "\n",
    "df['total_intl_calls'] = list_tmp\n",
    "\n",
    "df['total_intl_calls'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the % chance of guessing correctly if the customer was assumed to not churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df.churn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle state and total_intl_calls object types. Turn these into integers for later modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\",\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\",\n",
    "          \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\",\n",
    "          \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\",\n",
    "          \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_int = []\n",
    "for i, row in df.iterrows():\n",
    "    state_int.append(states.index(row['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_int'] = state_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intl_calls_int = []\n",
    "for i, row in df.iterrows():\n",
    "    if row['total_intl_calls'] == 'low':\n",
    "        intl_calls_int.append(0)\n",
    "    elif row['total_intl_calls'] == 'moderate':\n",
    "        intl_calls_int.append(1)\n",
    "    else:\n",
    "        intl_calls_int.append(2)\n",
    "\n",
    "df['intl_calls_bins'] = intl_calls_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['state_int', 'international plan', 'intl_calls_bins',\n",
    "        'customer service calls', 'voice mail plan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['churn']\n",
    "# dropping # vmail messages because its distribution isn't normal\n",
    "X = df.drop(['churn', 'total intl calls', 'number vmail messages',\n",
    "             'total_intl_calls', 'state'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing class imbalance with SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cats = X_train_resampled[cats]\n",
    "X_train_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle categorical values\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "ohe.fit(X_train_cats)\n",
    "X_train_ohe = pd.DataFrame(\n",
    "    ohe.transform(X_train_cats),\n",
    "    index=X_train_cats.index,\n",
    "    columns=np.hstack(ohe.categories_)\n",
    ")\n",
    "X_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerics = X_train_resampled.drop(cats, axis=1)\n",
    "X_train_numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling variables to work well with OHE data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train_numerics)\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_numerics),\n",
    "    index=X_train_numerics.index,\n",
    "    columns=X_train_numerics.columns\n",
    ")\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train_scaled, X_train_ohe], axis=1)\n",
    "X_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear',\n",
    "                            random_state=1)\n",
    "model_log = logreg.fit(X_train_full, y_train_resampled)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_hat_train = logreg.predict(X_train_full)\n",
    "\n",
    "train_residuals = np.abs(y_train_resampled - y_hat_train)\n",
    "print(pd.Series(train_residuals, name=\"Residuals (counts)\").value_counts())\n",
    "print()\n",
    "print(pd.Series(train_residuals, name=\"Residuals (proportions)\").value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set is about 80% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance evaluation on test set.\n",
    "X_test_cats = X_test[cats]\n",
    "\n",
    "# handle categorical values\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "ohe.fit(X_test_cats)\n",
    "X_test_ohe = pd.DataFrame(\n",
    "    ohe.transform(X_test_cats),\n",
    "    index=X_test_cats.index,\n",
    "    columns=np.hstack(ohe.categories_)\n",
    ")\n",
    "\n",
    "X_test_numerics = X_test.drop(cats, axis=1)\n",
    "\n",
    "# Scaling variables to work well with OHE data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_test_numerics)\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_numerics),\n",
    "    index=X_test_numerics.index,\n",
    "    columns=X_test_numerics.columns\n",
    ")\n",
    "\n",
    "X_test_full = pd.concat([X_test_scaled, X_test_ohe], axis=1)\n",
    "X_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = logreg.predict(X_test_full)\n",
    "\n",
    "test_residuals = np.abs(y_test - y_hat_test)\n",
    "print(pd.Series(test_residuals, name=\"Residuals (counts)\").value_counts())\n",
    "print()\n",
    "print(pd.Series(test_residuals, name=\"Residuals (proportions)\").value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set is about 73% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=13, random_state=1)\n",
    "forest.fit(X_train_full, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuracy\n",
    "forest.score(X_train_full, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Accuracy\n",
    "forest.score(X_test_full, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train_full.shape[1]\n",
    "    plt.figure(figsize=(8,16))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train_full.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - Optimize RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pipeline to select for optimal parameters in the RF Classifier\n",
    "pipe = Pipeline([('clf', RandomForestClassifier(random_state=1))])\n",
    "\n",
    "param_range = np.arange(1, 17, 1)\n",
    "\n",
    "grid_params = [{'clf__n_estimators': [100],\n",
    "                'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__max_depth': param_range,\n",
    "                'clf__min_samples_split': param_range[1:],\n",
    "                'clf__min_samples_leaf': param_range,}]\n",
    "\n",
    "# grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=grid_params,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "# Fit using grid search\n",
    "gs.fit(X_train_full, y_train_resampled)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
